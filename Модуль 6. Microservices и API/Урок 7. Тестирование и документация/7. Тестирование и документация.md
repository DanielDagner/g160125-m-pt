# Тестирование в программировании: конспект

## Основы тестирования

**Что такое тестирование?** Тестирование в программировании – это процесс проверки и оценки работы программного обеспечения на соответствие ожиданиям. Цель тестирования – выявить ошибки (баги) и убедиться, что программа ведет себя правильно во всех предусмотренных сценариях. Проще говоря, тестирование сопоставляет **фактическое поведение** программы с **ожидаемым поведением**, обнаруживая расхождения.

**Зачем нужно тестирование?** Без достаточного тестирования даже мелкие ошибки в коде могут привести к сбоям, неправильным расчетам или уязвимостям в безопасности. Тестирование позволяет находить и устранять проблемы на ранних этапах разработки, что значительно сокращает стоимость их исправления. Кроме того, хорошо протестированное приложение отличается более высоким качеством и надежностью, повышает удовлетворенность пользователей и доверие к продукту. Тесты служат своего рода защитной сеткой: при внесении изменений в код автоматические тесты помогут проверить, что новая функциональность не нарушила работу уже существующей (это называется регрессией).

**Какие бывают тесты?** Тестирование может выполняться **вручную** (инженер вручную проверяет работу приложения, следуя тестовым сценариям) или **автоматизировано** (с помощью специальных программ и скриптов). В процессе разработки ПО разработчики обычно пишут **автоматические тесты** на код с помощью специальных фреймворков. Существует множество видов тестирования (рассмотрим их ниже): от проверки отдельных функций (модульное тестирование) до проверки системы целиком под нагрузкой или в реальных условиях (например, нагрузочное или приемочное тестирование). Каждый вид тестирования нацелен на свой уровень проверки и вместе они обеспечивают всестороннюю оценку качества программы.

## Виды тестирования

В практике разработки принято разделять тестирование на различные виды в зависимости от охвата компонентов и целей проверки. Рассмотрим основные виды тестирования и их особенности:

### Модульное тестирование (Unit testing)

**Модульное тестирование** – это проверка отдельных небольших частей программы (модулей) в изоляции от остальных. В качестве *модуля* обычно выступает отдельная функция, метод класса или небольшой класс. Идея заключается в том, чтобы убедиться, что каждый такой элемент правильно работает сам по себе, независимо от внешнего окружения. 

Особенности модульного тестирования:
- Тесты пишутся, как правило, самими разработчиками кода и запускаются часто (например, при каждом изменении).
- Для изоляции внешние зависимости заменяются заглушками или мок-объектами (симуляторами), чтобы тест проверял только логику целевого модуля.
- Модульные тесты помогают быстро локализовать баги: если тест упал, то проблема, скорее всего, в конкретной функции или классе.

Пример: функция сложения двух чисел должна возвращать их сумму. Модульный тест для нее проверит несколько вариантов входных значений и убедится, что результат верный в каждом случае. (Примеры тестов для функции сложения приведены далее.)

### Интеграционное тестирование (Integration testing)

**Интеграционное тестирование** направлено на проверку взаимодействия между несколькими модулями или компонентами системы. После того как отдельные части (функции, модули) протестированы изолированно, важно убедиться, что в совокупности они корректно работают друг с другом.

Особенности интеграционного тестирования:
- Оно выявляет ошибки в местах стыков: несогласованность форматów данных, неправильное использование результатов одной функции в другой и т.д.
- Интеграционные тесты могут охватывать значительные участки системы, например, выполнение функции, которая внутри себя вызывает другие модули, обращается к базе данных, к внешним сервисам и т.п.
- Иногда интеграционное тестирование разделяют на поэтапное: сначала объединяют два модуля, проверяют их в связке, затем подключают третий и т.д., постепенно тестируя всю систему в комплексе.

Пример: модуль обработки заказов взаимодействует с модулем оплаты. Модульный тест каждого из них отдельно может проходить успешно, но интеграционный тест может выявить, что данные о сумме заказа некорректно передаются в систему оплаты (например, валюта не та или формат числа неверен). Интеграционное тестирование помогает обнаружить подобные проблемы **на уровне взаимодействия компонентов**. 

### Функциональное тестирование

**Функциональное тестирование** проверяет, что программное обеспечение выполняет все заявленные **функциональные требования**. По сути, это проверка всех **функций и возможностей** приложения с точки зрения пользователя или спецификации. Здесь под "функцией" понимается не функция в коде, а функциональность или требование – например, возможность зарегистрироваться на сайте, оформить заказ, рассчитать значение по формуле и т.д.

Особенности функционального тестирования:
- Обычно проводится на полнофункциональной системе (или значительной ее части) без внимания к внутренней реализации (это **черный ящик** – мы знаем, что должно происходить, но не обязательно как именно это реализовано).
- Проверяются как **позитивные сценарии** (правильные данные, ожидаемое поведение), так и **негативные сценарии** (неправильные данные, неожиданные действия пользователя) с точки зрения функциональности.
- Функциональные тесты могут выполняться вручную (QA-инженером по тест-кейсам) или автоматизированно (например, с помощью UI-тестов, API-тестов и т.п.).

Пример: для калькулятора функциональный тест проверит, что при вводе 2 + 2 и нажатии "=" отображается результат 4. Также функциональный тест на веб-приложении может проверить, что пользователь может успешно пройти весь путь от регистрации до оформления заказа, и система на каждом шаге ведет себя согласно требованиям.

### Нагрузочное тестирование (и другие виды производительных тестов)

**Нагрузочное тестирование** (performance/load testing) проверяет работу системы при повышенной нагрузке: большое число одновременных пользователей, большой объем данных, высокая интенсивность запросов и т.п. Цель – выявить пределы производительности, стабильности и надежности приложения. Разновидности производительных тестов включают стресс-тестирование (экстремальные нагрузки, выход за пределы нормальных условий), тестирование стабильности/длительной нагрузки (проверка работы под нагрузкой в течение длительного времени, например, memory leak тесты) и т.д.

Особенности нагрузочного тестирования:
- Часто проводится с использованием специальных инструментов или сервисов, которые могут симулировать сотни и тысячи одновременных запросов (например, JMeter, Locust, ab и др.).
- Метрики, на которые смотрят: время отклика системы, пропускная способность (сколько запросов в секунду обслуживается), использование ресурсов (CPU, память) и наличие сбоев при нагрузке.
- Результаты нагрузочного тестирования помогают оптимизировать код и инфраструктуру: например, обнаружить узкие места (bottlenecks) и понять, при каком количестве пользователей система перестанет справляться.

Пример: для веб-сайта интернет-магазина можно провести нагрузочное тестирование, постепенно увеличивая число одновременно просматривающих товары пользователей, чтобы убедиться, что сайт не станет значительно тормозить или падать при большом наплыве посетителей (скажем, в период распродажи).

### Негативное тестирование (Negative testing)

**Негативное тестирование** проверяет устойчивость программы к некорректным данным и ситуациям. В отличие от *позитивных* тестов, где мы проверяем работу на корректных, ожидаемых входных данных, негативные тесты намеренно используют неверные, необычные или экстремальные данные, чтобы убедиться, что система ведет себя предсказуемо: выдает понятные ошибки, не разрушается, не дает неверных результатов.

Особенности негативного тестирования:
- Покрывает сценарии "что будет, если...": например, пользователь вводит буквы туда, где ожидаются цифры; или файл не найден; или получена пустая строка вместо нужных данных; или запрос пришел с ошибкой.
- Система должна обработать такие случаи должным образом: выбросить исключение, вернуть код ошибки, показать сообщение об ошибке – **главное, не выйти из строя и не дать некорректного результата** без предупреждения.
- Негативные тесты часто пишутся на уровне модулей (например, проверка, что функция выбрасывает исключение при отрицательном аргументе) и на уровне системы (например, попытка авторизации с неправильным паролем должна возвращать сообщение об ошибке).

Пример: функция расчета скидки должна выдать ошибку, если передать процент скидки больше 100% или отрицательный – это типичный негативный тест на проверку граничных условий. Ещё пример – тест на попытку открыть файл, которого нет: функция должна не крашнуться, а корректно обработать эту ситуацию (вернуть ошибку или исключение). Негативное тестирование улучшает надежность ПО за счет учета неожиданных ситуаций.

### Другие виды тестирования

Кроме перечисленных, существуют и другие важные виды тестирования, например:

- **Регрессионное тестирование** – повторное прогоняние набора тестов (или специальных регрессионных тест-кейсов) после внесения изменений в код, чтобы убедиться, что новое изменение не нарушило уже работающий функционал. Автоматические модульные и интеграционные тесты идеально подходят для регрессии: их регулярно запускают при каждом обновлении приложения.
- **Приемочное тестирование** – финальная проверка продукта на соответствие требованиям заказчика перед выпуском. Обычно проводится либо командой QA, либо самими заказчиками/конечными пользователями (beta-тестирование). Цель – подтвердить, что система решает поставленные бизнес-задачи и готова к эксплуатации.
- **Системное тестирование** – проверка всей системы целиком в максимально приближенных к реальным условиях. Например, запуск веб-приложения целиком на тестовом сервере и проверка всех его модулей совместно, включая интеграцию с внешними сервисами, базами данных и т.д. Это широкое испытание всего продукта как единого целого.
- **Smoke-тестирование** – короткий набор самых основных тестов, чтобы убедиться, что сборка или новая версия приложения хотя бы запускается и выполняет ключевые функции (образно: "не разваливается при включении"). Чаще всего это быстрая проверка перед более глубоким тестированием.
- **Эксплуатационное/бета-тестирование** – испытание программы реальными пользователями в реальной среде, чтобы получить обратную связь, обнаружить нестандартные проблемы, не учтенные на этапах разработки.

Каждый вид тестирования дополняет другие. На практике, для обеспечения качества, используют **комбинацию подходов**: разработчики пишут модульные тесты, тестировщики запускают интеграционные и функциональные сценарии, команда производительности проводит нагрузочные тесты и т.д. В итоге все это помогает выпустить стабильный продукт.

## Инструменты для тестирования (Python и Pytest)

Для написания и выполнения автоматических тестов используются специальные инструменты – **тестовые фреймворки**. В экосистеме Python популярны следующие инструменты:

- **unittest** – встроенный в стандартную библиотеку Python модуль для создания тестов. Предлагает классический подход xUnit (как JUnit в Java): тесты оформляются как методы класса, используются специальные методы `assertEqual`, `assertTrue` и т.д. Несмотря на распространенность, синтаксис unittest довольно громоздкий.
- **pytest** – мощный и удобный фреймворк для тестирования Python-кода. Pytest упрощает написание тестов: вместо классов достаточно писать функции, проверки осуществляются простым оператором `assert`, а набор возможностей очень широк (фикстуры, параметризация, хуки, плагины и др.). Благодаря своей простоте и расширяемости, pytest сегодня наиболее популярен среди Python-разработчиков.
- **doctest** – модуль, позволяющий выполнять фрагменты кода, указанные в строках документации (docstring) ваших функций, и проверять, совпадает ли вывод с ожидаемым. Полезен для простых случаев и примеров в документации, но не заменяет полноценные тесты.
- **nose** – когда-то был популярным фреймворком, расширяющим unittest, но сейчас фактически не развивается, и сообщество перешло на pytest.

В рамках этого конспекта мы сфокусируемся на **pytest**, как на одном из самых удобных инструментов тестирования в Python.

### Особенности и возможности Pytest

- **Простота написания тестов:** чтобы написать тест, достаточно создать функцию, имя которой начинается с `test_`, и внутри использовать обычные утверждения Python (`assert`). Pytest сам обнаружит такие функции и запустит их. Это делает тесты очень читабельными и короткими.

- **Автоматическое обнаружение тестов:** фреймворк сам находит все файлы, начинающиеся с `test_` (или заканчивающиеся на `_test.py`), и запускает содержащиеся в них тестовые функции. Нет необходимости вручную регистрировать тесты – достаточно соблюдать соглашение об именовании.

- **Фикстуры (fixtures):** это механизм подготовки и очистки окружения для тестов. С помощью фикстур можно, например, создавать временные файлы, подключать тестовую базу данных, подготавливать тестовые данные перед выполнением теста и автоматически освобождать ресурсы после. Pytest позволяет легко определить фикстуру с помощью декоратора `@pytest.fixture` и затем указать ее в списке параметров тестовой функции – pytest сам вызовет фикстуру и передаст ее результат в тест. Фикстуры повышают **повторное использование кода** и делают тесты чище (нет дублирующей подготовки данных в каждом тесте).

- **Параметризация тестов:** с помощью декоратора `@pytest.mark.parametrize` можно запустить один и тот же тест с разными наборами входных данных и ожиданий. Это удобнее и нагляднее, чем писать много однотипных функций или делать вручную цикл внутри теста. Pytest отобразит каждый такой прогон как отдельный тестовый случай. Параметризация помогает покрыть больше сценариев с меньшим количеством кода.

- **Плагины и расширяемость:** Pytest имеет богатую экосистему плагинов – для измерения покрытия кода (coverage), для тестирования веб-приложений (например, `pytest-django`, `pytest-flask`), для параллельного запуска тестов (`pytest-xdist`), гибкой настройки отчетов и многое другое. Можно писать и свои плагины, если требуется специальная логика при выполнении тестов.

- **Маркировка тестов:** можно помечать тесты специальными метками (markers), например `@pytest.mark.slow` для пометки медленных тестов, или `@pytest.mark.skip` чтобы пропустить тест в определенных условиях. Запуская тесты, можно отфильтровать или отключить некоторые группы по меткам.

- **Удобный вывод и отчеты:** при падении теста pytest предоставляет подробный вывод: он **встраивает значения** переменных в выражении `assert` прямо в сообщение об ошибке (т.н. *assert introspection*). Например, если утверждение было `assert add(2,2) == 5`, отчет покажет что левая часть равна 4, а правая 5, что упрощает отладку. Кроме того, есть поддержка цветного вывода в терминале, форматы отчетов в файлы и т.д.

**Как использовать pytest?** Обычно достаточно установить пакет (`pip install pytest`) и написать тестовые функции в файлах, названных `test_*.py`. Запуск тестов – командой `pytest` в терминале из корневой директории проекта. Pytest найдет и выполнит все тесты, выведет отчет о количестве пройденных/проваленных тестов. Например, простой тест:

```python
# example.py – код, который нужно протестировать
def multiply(a, b):
    return a * b

# test_example.py – файл с тестами
from example import multiply

def test_multiply():
    assert multiply(2, 3) == 6  # проверяем, что 2*3 действительно 6
```

При запуске `pytest` фреймворк найдет `test_example.py`, выполнит функцию `test_multiply`. Если результат выражения соответствует ожиданию, тест считается пройденным; если нет – выводится сообщение об ошибке. В следующих разделах мы рассмотрим практические примеры тестирования с помощью pytest на конкретных задачах.

## Практические примеры тестирования

Разберем несколько практических примеров, используя файлы с кодом и тестами. Эти примеры демонстрируют различные аспекты тестирования: от простых модульных тестов до параметризации, проверки исключений, граничных значений, использования фикстур и интеграционного тестирования веб-API. Предположим, у нас есть соответствующие файлы с реализацией функций и файлы с тестами для них.

### Простые тесты для функций сложения (`add.py`, `add_f.py`)

Для начала рассмотрим простейший случай: есть две функции, складывающие два числа. Первая функция `add` складывает два целых числа, вторая `add_f` – складывает два числа с плавающей точкой (в нашем примере можно считать, что она предназначена для вещественных чисел). Наша задача – написать модульные тесты, которые проверят корректность их работы на нескольких примерах.

**Код функций (файл `add.py` и `add_f.py`):**

```python
# add.py
def add(a, b):
    """Возвращает сумму a и b (целые числа)."""
    return a + b

# add_f.py
def add_f(a, b):
    """Возвращает сумму a и b (числа с плавающей точкой)."""
    return a + b
```

Обе функции довольно тривиальны – они просто используют оператор `+`. Тем не менее, мы напишем для них тесты, чтобы убедиться, что при различных входных данных они ведут себя как ожидается.

**Пример тестов (файл `test_add.py`):**

```python
from add import add
from add_f import add_f

def test_add_integers():
    # Проверяем несколько вариантов для целых чисел
    assert add(2, 3) == 5          # 2 + 3 = 5
    assert add(-1, 1) == 0         # -1 + 1 = 0
    assert add(0, 0) == 0          # 0 + 0 = 0

def test_add_floats():
    # Проверяем сложение для чисел с плавающей точкой
    result = add_f(0.5, 0.5)
    assert result == 1.0           # 0.5 + 0.5 = 1.0

    # Также убеждаемся, что функция работает и с "целочисленными" аргументами, возвращая float
    result2 = add_f(2, 3)
    assert isinstance(result2, float) and result2 == 5.0
```

В тестах мы вызвали функции с различными значениями и проверили, что возвращаемый результат соответствует математике. Для `add` мы проверили сложение положительных, отрицательных и нулевых целых. Для `add_f` убедились, что сумма 0.5 и 0.5 дает 1.0 (это проверка с вещественными числами), а также что если даже передать ей целые числа, она вернет результат как `float`. 

Обратите внимание, что мы используем несколько утверждений `assert` внутри одного теста – это допустимо. Если какое-то из них не пройдет, тест упадет на первой же неудаче. Можно было разбить их на отдельные функции для каждого случая, но здесь, поскольку логика одинаковая (сложение), допустимо сгруппировать несколько проверок в одном тесте для компактности.

Запустив `pytest`, мы ожидаем, что оба теста (`test_add_integers` и `test_add_floats`) пройдут без ошибок, так как функции определены правильно.

### Тестирование с параметризацией (`test_param_add.py`)

Во втором примере покажем, как с помощью параметризации можно сократить код тестов, проверяющих одну и ту же функцию на разных входных данных. Возьмем снова функцию `add` (сложение двух чисел). Вместо того чтобы писать много отдельных тест-функций или нескольких `assert` в одном тесте, мы используем декоратор `@pytest.mark.parametrize` для перебора наборов значений.

**Пример параметризованного теста (файл `test_param_add.py`):**

```python
import pytest
from add import add

@pytest.mark.parametrize("a, b, expected", [
    (1, 2, 3),      # 1+2=3
    (0, 0, 0),      # 0+0=0
    (-5, 5, 0),     # -5+5=0
    (10, -3, 7),    # 10+(-3)=7
    (100, 200, 300) # 100+200=300
])
def test_add_param(a, b, expected):
    """Параметризованный тест для функции add."""
    result = add(a, b)
    assert result == expected
```

Здесь декоратор `@pytest.mark.parametrize` задает, что тестовую функцию `test_add_param` нужно выполнить несколько раз, подставляя на каждую итерацию очередной кортеж значений `(a, b, expected)` из списка. В примере мы пять раз запустим тест с разными цифрами. Pytest отобразит это как пять отдельных тест-кейсов (с указанием параметров в имени теста). 

Преимущество такого подхода – в явном перечислении тестовых случаев в компактной форме. Если какой-то из них не пройдет, отчет покажет, на каком наборе параметров произошла ошибка. Например, если функция `add` была бы реализована неверно, скажем, вычитала бы числа, то несколько из параметризованных проверок провалились бы, и разработчик сразу увидел бы, на каких входных данных получен неверный результат.

Таким образом, параметризация позволяет легко масштабировать количество проверок без дублирования кода, что делает тесты чище и поддерживаемее.

### Негативные тесты и работа с исключениями (`calculate_discount.py`, `test_calculate_discount.py`)

Следующий пример демонстрирует **негативное тестирование** на уровне модулей и проверку работы с исключениями. Пусть у нас есть функция `calculate_discount` в файле `calculate_discount.py`, которая рассчитывает цену товара после применения скидки. Функция принимает два аргумента: исходную цену и процент скидки. Очевидно, процент скидки должен быть от 0 до 100. Если передать некорректное значение (например, 150% или -20%), функция должна **сгенерировать исключение** `ValueError`, сигнализирующее об ошибке в аргументах. В остальных случаях функция рассчитывает новую цену.

**Код функции (файл `calculate_discount.py`):**

```python
# calculate_discount.py
def calculate_discount(price, discount_percent):
    """
    Вычисляет цену после применения скидки discount_percent%.
    Если discount_percent вне диапазона 0-100, выбрасывает ValueError.
    """
    if discount_percent < 0 or discount_percent > 100:
        raise ValueError("Discount percent must be between 0 and 100")
    # Цена после скидки:
    return price * (100 - discount_percent) / 100
```

Теперь напишем тесты, которые покрывают как **позитивные**, так и **негативные** случаи использования этой функции.

**Пример тестов (файл `test_calculate_discount.py`):**

```python
import pytest
from calculate_discount import calculate_discount

def test_calculate_discount_valid():
    # Проверка корректного расчета
    assert calculate_discount(200, 25) == 150   # 25% от 200 -> цена должна стать 150
    assert calculate_discount(100, 0) == 100    # 0% скидки, цена не меняется
    assert calculate_discount(50, 100) == 0     # 100% скидка, цена становится 0

def test_calculate_discount_invalid_negative():
    # Негативный тест: отрицательный процент скидки должен вызывать исключение
    with pytest.raises(ValueError):
        calculate_discount(100, -5)

def test_calculate_discount_invalid_over():
    # Негативный тест: процент скидки больше 100 должен вызывать исключение
    with pytest.raises(ValueError):
        calculate_discount(100, 150)
```

Разберем эти тесты:
- `test_calculate_discount_valid`: позитивные проверки на правильность вычислений. Мы протестировали несколько граничных случаев: обычную скидку 25%, нулевую скидку, полную скидку 100%. Функция должна вернуть ожидаемые новые цены.
- `test_calculate_discount_invalid_negative`: здесь используется конструкция `with pytest.raises(ValueError)`. Это стандартный способ в pytest убедиться, что вызов внутри блока `with` выбросит указанное исключение (`ValueError` в данном случае). Мы передаем заведомо неверный аргумент `-5`% и ожидаем, что функция не вернет значение, а возбудит исключение.
- `test_calculate_discount_invalid_over`: аналогично, проверяем, что 150% скидки приводит к исключению.

Использование `pytest.raises` позволяет явно отловить и проверить исключение. Если функция не выбросит `ValueError` там, где должна, тест будет отмечен как провалившийся. Если же неожиданно выбросится исключение другого типа, pytest тоже это заметит (тест упадет, так как искомого ValueError не произошло). Таким образом, мы удостоверяемся, что функция надежно обрабатывает некорректные ситуации.

Этот пример иллюстрирует принцип негативного тестирования: мы специально проверяем, что на **неправильные входные данные** наш код реагирует корректно (в данном случае – правильным выбросом ошибки), а не просто "падает" или, хуже того, возвращает какой-то бессмысленный результат.

### Проверка граничных значений (`is_prime.py`, `test_is_prime.py`)

При тестировании функций часто важно проверить **граничные условия** – экстремальные или переходные значения параметров, на которых легко допустить ошибку. Рассмотрим функцию `is_prime` (файл `is_prime.py`), которая определяет, является ли переданное число простым. Граничными случаями для такой задачи будут: очень маленькие числа (0, 1, 2), отрицательные числа, а также, возможно, какие-то большие числа, чтобы убедиться в эффективности. Но основной интерес представляют 0 и 1 – они не являются простыми, и программа должна правильно это обрабатывать, хотя эти числа часто вызывают ошибку у неопытных разработчиков, пишущих функции проверки простоты.

**Код функции (файл `is_prime.py`):**

```python
# is_prime.py
def is_prime(n):
    """
    Возвращает True, если n - простое число, и False в противном случае.
    Простое число - больше 1 и делится только на 1 и само на себя.
    """
    if n < 2:
        return False
    # Проверяем делители от 2 до sqrt(n)
    limit = int(n ** 0.5) + 1
    for i in range(2, limit):
        if n % i == 0:
            return False
    return True
```

Эта функция сначала отсекает все числа меньше 2 (для них сразу возвращается False), затем проверяет делимость на все числа от 2 до квадратного корня из n. Если ни один из делителей не подошел, число простое.

Теперь напишем тесты, уделив особое внимание граничным значениям: 0, 1, 2, а также парочке обычных случаев и негативных (например, отрицательные числа).

**Пример тестов (файл `test_is_prime.py`):**

```python
from is_prime import is_prime

def test_is_prime_basic():
    # Базовые случаи для простых и составных чисел
    assert is_prime(2) is True    # 2 - простое (минимальное простое число)
    assert is_prime(3) is True    # 3 - простое
    assert is_prime(4) is False   # 4 - не простое (делится на 2)
    assert is_prime(16) is False  # 16 - не простое (4*4)

def test_is_prime_edge_cases():
    # Граничные значения
    assert is_prime(0) is False   # 0 не является простым по определению
    assert is_prime(1) is False   # 1 не простое
    assert is_prime(-10) is False # отрицательные числа не простые (по определению)

def test_is_prime_large():
    # Проверяем для некоторого большого простого и большого составного числа
    assert is_prime(97) is True   # 97 - простое число
    assert is_prime(100) is False # 100 - составное (делится на 2, 4, 5, etc)
```

Разберем, что мы проверили:
- В `test_is_prime_basic` убедились, что функция правильно различает явные простые и составные числа (2, 3 должны быть True; 4, 16 – False).
- В `test_is_prime_edge_cases` протестированы граничные случаи: 0 и 1 должны давать False (это часто оговаривается в определении простых чисел), отрицательное число тоже возвращает False. Эти случаи важно проверять, т.к. если бы в функции забыли условие `if n < 2: return False`, то на 0 или 1 цикл проверки мог бы дать неверный результат или даже сгенерировать ошибку.
- `test_is_prime_large` не обязательно охватывает "крайние" значения, но показывает, что мы можем тестировать и более крупные числа. Здесь 97 известен как простое число, а 100 очевидно составное.

Граничное тестирование важно тем, что ошибки часто скрываются именно на краях диапазонов: например, перепутать условие строгости (`< 2` вместо `<= 1`), не учесть отрицательные, неверно обработать максимум допустимого значения и т.п. В тестах на такие случаи уделяется особое внимание.

### Работа с фикстурами и тестирование фильтрации данных (`filter_dicts.py`, `test_filter_dicts.py`)

В этом примере рассмотрим использование **фикстур** pytest для подготовки данных, а заодно протестируем функцию фильтрации данных. Пусть у нас есть функция `filter_dicts` (файл `filter_dicts.py`), которая принимает список словарей и пороговое значение, и возвращает новый список, состоящий только из тех словарей, где определенный показатель (например, поле `'value'`) не ниже заданного порога. 

Задача: написать тест, который проверит, что фильтрация работает правильно. При этом в нескольких тестах нам может понадобиться один и тот же исходный список словарей – чтобы не дублировать его в каждом тесте, удобно воспользоваться фикстурой, возвращающей этот список.

**Код функции (файл `filter_dicts.py`):**

```python
# filter_dicts.py
def filter_dicts(dicts_list, threshold):
    """
    Возвращает список словарей из dicts_list, у которых значение по ключу 'value'
    больше или равно threshold.
    """
    return [d for d in dicts_list if d.get('value', 0) >= threshold]
```

Здесь мы предполагаем, что каждый словарь имеет ключ `'value'`, по которому нужно фильтровать. Если вдруг ключа нет, через `d.get('value', 0)` мы подставим 0 (такие элементы не пройдут фильтр, что логично). Теперь тесты.

**Пример тестов с фикстурой (файл `test_filter_dicts.py`):**

```python
import pytest
from filter_dicts import filter_dicts

# Фикстура для подготовки данных – список словарей
@pytest.fixture
def sample_data():
    return [
        {"name": "A", "value": 5},
        {"name": "B", "value": 10},
        {"name": "C", "value": 3},
        {"name": "D", "value": 8}
    ]

def test_filter_dicts(sample_data):
    # Используем подготовленный список sample_data для теста
    result = filter_dicts(sample_data, threshold=5)
    # Ожидаем, что вернутся элементы с value >= 5 (т.е. A, B, D)
    assert result == [
        {"name": "A", "value": 5},
        {"name": "B", "value": 10},
        {"name": "D", "value": 8}
    ]

def test_filter_dicts_no_match(sample_data):
    # Проверяем случай, когда ни один словарь не удовлетворяет условию
    result = filter_dicts(sample_data, threshold=11)
    assert result == []  # порог выше любого value, должно вернуться пусто

def test_filter_dicts_all_pass(sample_data):
    # Случай, когда все элементы проходят (порог 3 - минимальное значение в данных)
    result = filter_dicts(sample_data, threshold=3)
    # Результат должен содержать все исходные словари, кроме тех, у кого value < 3 (таких нет, т.к. минимум 3 включен)
    assert result == sample_data
```

Объясним, что происходит:
- Мы определили фикстуру `sample_data()`. Эта функция помечена декоратором `@pytest.fixture`, поэтому pytest перед запуском тестов знает, что она может быть использована как источник данных. Фикстура возвращает список словарей с разными значениями `'value'`.
- Каждый из тестов принимает параметр `sample_data` – именно так мы сообщаем pytest, что этому тесту нужна соответствующая фикстура. Перед выполнением теста `sample_data` pytest вызовет функцию-фикстуру и передаст ее результат как аргумент.
- В `test_filter_dicts` мы фильтруем `sample_data` с порогом 5. Ожидаем, что словари с `'value'` 5, 8, 10 пройдут фильтр, а словарь с `'value': 3` будет отброшен. Результат проверяем через точное сравнение списков.
- В `test_filter_dicts_no_match` проверяется ситуация, когда порог выше любого значения в списке – ожидаем пустой список.
- В `test_filter_dicts_all_pass` ставим порог равный минимальному значению в данных (3), поэтому должны пройти все элементы (никто не отфильтруется). Здесь для проверки мы сравнили результат прямо с `sample_data` – т.к. порядок элементов сохраняется в понимании нашей функции (фильтр проходит по исходному списку), это корректно.

Использование фикстуры сделало код тестов чище: мы определили тестовые данные один раз, а не копировали этот список в каждый тест. Кроме того, если бы нам понадобилось изменить или расширить `sample_data`, мы сделали бы это в одном месте. Pytest позволяет определять фикстуры даже в отдельных файлах (`conftest.py`) и делать их доступными для множества тестовых модулей – это мощный способ организации повторно используемого настроечного кода.

### Интеграционное тестирование API (`main.py`, `test_api.py`)

Напоследок рассмотрим пример интеграционного теста для веб-приложения (API). Представим, что у нас есть простой веб-сервис с одним эндпойнтом, реализованный, например, с помощью фреймворка **FastAPI** (один из современных фреймворков для создания API на Python). В файле `main.py` определяется приложение `app` и маршрут (endpoint), который принимает некоторые параметры и возвращает результат в формате JSON. Мы напишем интеграционный тест `test_api.py`, который запускает это приложение в тестовом режиме и проверяет, что при запросе к маршруту приходит правильный ответ. 

Почему это считается интеграционным тестом? Потому что здесь мы тестируем сразу несколько частей системы в комплексе: работу веб-сервиса (роутинг, обработка запросов) и бизнес-логику внутри обработчика. Мы не вызываем напрямую функцию Python, а именно делаем HTTP-запрос к приложению, что максимально приближено к реальному использованию API.

**Код приложения (файл `main.py`):**

```python
# main.py
from fastapi import FastAPI

app = FastAPI()

@app.get("/add")
def add_endpoint(a: int, b: int):
    """
    Эндпойнт, возвращающий сумму двух чисел a и b.
    Параметры a и b передаются как query-параметры в запросе.
    """
    return {"result": a + b}
```

В этом приложении определен GET-запрос `/add`, который принимает два параметра (`a` и `b` в query string). Он возвращает JSON с полем `"result"`, равным сумме `a + b`. Например, запрос `/add?a=2&b=3` вернет JSON `{"result": 5}`.

Теперь интеграционный тест для этого API. В FastAPI (как и во Flask) есть встроенный механизм для тестирования – **тестовый клиент**. В FastAPI используется `TestClient` из библиотеки starlette (входит в FastAPI). Он позволяет вызывать маршруты приложения, не поднимая реальный сервер, а напрямую в коде, что удобно и быстро.

**Код теста (файл `test_api.py`):**

```python
from fastapi.testclient import TestClient
from main import app

client = TestClient(app)  # создаем тестовый клиент для нашего приложения

def test_add_endpoint():
    # Отправляем GET-запрос на эндпойнт /add с параметрами a=2, b=3
    response = client.get("/add", params={"a": 2, "b": 3})
    # Проверяем, что ответ пришел с HTTP статусом 200 (OK)
    assert response.status_code == 200
    # Проверяем, что тело ответа (JSON) содержит ожидаемый результат
    assert response.json() == {"result": 5}
```

В этом тесте мы:
- Инициализировали `TestClient`, передав ему наше приложение `app`. Теперь можем через этот объект посылать запросы.
- С помощью `client.get()` отправили запрос на адрес `/add` с нужными параметрами. `response` – это объект, содержащий то, что вернулось от приложения.
- Проверили `response.status_code` – он должен быть 200, то есть запрос успешен.
- Проверили содержимое JSON-ответа методом `response.json()` – оно должно точно совпадать с ожидаемым словарем `{"result": 5}`.

Таким образом, мы протестировали весь путь: запрос попадает в наше приложение, парсится, попадает в функцию `add_endpoint`, та считает сумму и возвращает результат, который клиент получает. Если, например, в нашем коде `add_endpoint` была бы ошибка (неправильное имя параметра, ошибка в логике), тест бы это выявил.

Интеграционные тесты подобного рода очень полезны для проверки веб-приложений. Их можно расширять, тестируя разные эндпойнты, разные комбинации параметров, а также ошибки (например, что происходит, если не передать обязательный параметр `a` или передать не число — можно проверить, что приходит код ошибки 422 с сообщением об ошибке в запросе, так как FastAPI валидирует входные данные).

**Замечание:** Если бы мы использовали Flask, код приложения и теста был бы чуть другим (в Flask, например, нужно использовать `app.test_client()`), но идея та же: вызывать эндпойнт и проверять ответ. Фреймворк FastAPI у нас здесь просто для примера, с pytest он отлично дружит.

## Заключение

Мы рассмотрели основные понятия тестирования в программировании, типы тестов и инструмент pytest, а также пошагово прошлись по реальным примерам тестирования различных сценариев:
- Модульные тесты простой функции.
- Параметризация тестов для компактного описания множества проверок.
- Негативные тесты и проверка генерации исключений.
- Тестирование граничных условий работы функции.
- Использование фикстур для подготовки данных и повторного использования кода в тестах.
- Интеграционное тестирование веб-приложения через его API.

Хорошее покрытие кода тестами помогает обеспечить качество и надежность программ. При работе над любым более-менее сложным проектом важно писать тесты на ключевые компоненты. Начинать можно с модульных тестов на отдельные функции, затем добавлять интеграционные сценарии. Pytest, благодаря своей простоте и мощи, позволяет быстро написать и запустить весь этот спектр тестов. 

Помните: тестирование – неотъемлемая часть процесса разработки. Чем раньше находятся и устраняются ошибки, тем стабильнее и успешнее будет конечный продукт. Автоматические тесты экономят время в долгосрочной перспективе, потому что выполняют рутинную проверку вместо человека и сразу сигнализируют, если что-то пошло не так. Используя инструменты вроде pytest и грамотно сочетая разные виды тестирования, вы значительно повышаете качество вашего кода и снижаете риск нежелательных сюрпризов при его использовании.